{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.10.2 is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import metrics\n",
    "from utils import datasets, dataset_loader_two_tfs, test_dataset_loader\n",
    "from network import MTL_Model, ConvNet\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    print('Torch',torch.__version__, 'is available')\n",
    "else:\n",
    "    print('Torch is not available. Process is terminated')\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Binding Prediction for ARID3A and ZBTB7A\n",
      "Searching for all hyperparameter settings...\n"
     ]
    }
   ],
   "source": [
    "# tfs = args.TF\n",
    "tfs = ['ARID3A', 'ZBTB7A']\n",
    "CodeTesting = True\n",
    "print('TF Binding Prediction for', tfs[0], 'and', tfs[1])\n",
    "print('Searching for all hyperparameter settings...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases : 1\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 150\n",
    "reverse_mode = False\n",
    "num_motif_detector = 16\n",
    "motif_len =24\n",
    "batch_size = 64\n",
    "beta1 = 2*10**-6\n",
    "beta2 = 5*10**-6\n",
    "beta3 = 2*10**-6\n",
    "if CodeTesting:\n",
    "    pool_type = ['max']\n",
    "    hidden_layer_type = [True] # add one hidden layer or not\n",
    "    dropout_rate_type = [0.2]\n",
    "    lr_type = [0.01]\n",
    "    scheduler_type = [True] # use Cosine Annealing or not\n",
    "    opt_type = ['Adam'] # optimizer\n",
    "\n",
    "# total_cases = len(pool_type)*len(hidden_layer_type)*len(dropout_rate_type)*len(lr_type_sgd)*len(scheduler_type)*len(opt_type)\n",
    "total_cases = len(pool_type)*len(hidden_layer_type)*len(dropout_rate_type)*len(lr_type)*len(scheduler_type)*len(opt_type)\n",
    "\n",
    "print('Total cases :', total_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARID3A idx : 0\n",
      "ZBTB7A idx : 9\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# dataset\n",
    "path = './data/encode/'\n",
    "all_dataset_names = datasets(path)\n",
    "TF_to_idx = {'ARID3A' : 0, 'CTCFL' : 1, 'ELK1' : 2, 'FOXA1' : 3, 'GABPA' : 4, 'MYC' : 5, 'REST' : 6, 'SP1' : 7, 'USF1' : 8, 'ZBTB7A' : 9}\n",
    "TF1_idx = TF_to_idx[tfs[0]]\n",
    "TF2_idx = TF_to_idx[tfs[1]]\n",
    "if(CodeTesting):\n",
    "    print(f'{tfs[0]} idx : {TF1_idx}')\n",
    "    print(f'{tfs[1]} idx : {TF2_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1_dataset_name = all_dataset_names[TF1_idx]\n",
    "tf1_train_dataset_path = tf1_dataset_name[0]\n",
    "tf1_test_dataset_path = tf1_dataset_name[1]\n",
    "tf1_name = tf1_train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
    "\n",
    "tf2_dataset_name = all_dataset_names[TF2_idx]\n",
    "tf2_train_dataset_path = tf2_dataset_name[0]\n",
    "tf2_test_dataset_path = tf2_dataset_name[1]\n",
    "tf2_name = tf2_train_dataset_path.split(path)[1].split(\"_AC\")[0]\n",
    "\n",
    "# append할때 순서를 섞어줘야하나???\n",
    "train_data_loader, valid_data_loader, all_data_loader = dataset_loader_two_tfs(tf1_train_dataset_path, tf2_train_dataset_path, batch_size, reverse_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training\n"
     ]
    }
   ],
   "source": [
    "print('Model Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify hyperparameters\n",
    "case_num = 1\n",
    "(share, remainder) = divmod(case_num, len(opt_type))\n",
    "opt = opt_type[remainder]\n",
    "(share, remainder) = divmod(share, len(scheduler_type))\n",
    "scheduler = scheduler_type[remainder]\n",
    "(share, remainder) = divmod(share, len(lr_type))\n",
    "lr = lr_type[remainder]\n",
    "(share, remainder) = divmod(share, len(dropout_rate_type))\n",
    "dropout_rate = dropout_rate_type[remainder]\n",
    "(share, remainder) = divmod(share, len(hidden_layer_type))\n",
    "hidden_layer = hidden_layer_type[remainder]\n",
    "(share, remainder) = divmod(share, len(pool_type))\n",
    "pool = pool_type[remainder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTL_Model(num_motif_detector,motif_len,pool,hidden_layer,'training',lr,opt, dropout_rate,beta1,beta2,beta3,device,reverse_complemet_mode=False)\n",
    "\n",
    "# optimizer\n",
    "if hidden_layer == True:\n",
    "    if opt == 'SGD':\n",
    "        print('not possible')\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD([\n",
    "            model.net1.wConv,model.net1.wRect,model.net1.wNeu,model.net1.wNeuBias,model.net1.wHidden,model.net1.wHiddenBias,\n",
    "            model.net2.wConv,model.net2.wRect,model.net2.wNeu,model.net2.wNeuBias,model.net2.wHidden,model.net2.wHiddenBias\n",
    "        ], lr = lr)\n",
    "else:\n",
    "    print('not possible')\n",
    "\n",
    "# scheduler\n",
    "if scheduler == True:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0)\n",
    "else:\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, end_factor=1) # constant learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_data_loader\n",
    "valid_loader = valid_data_loader\n",
    "\n",
    "best_AUC_1 = 0\n",
    "best_AUC_2 = 0\n",
    "\n",
    "with open(\"./test/\"+'2020_4_7'+'.txt', \"a\") as file:\n",
    "    file.write('Train AUC over epochs : ')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th epoch over  150\n",
      "10 th epoch over  150\n",
      "20 th epoch over  150\n",
      "30 th epoch over  150\n",
      "40 th epoch over  150\n",
      "50 th epoch over  150\n",
      "60 th epoch over  150\n",
      "70 th epoch over  150\n",
      "80 th epoch over  150\n",
      "90 th epoch over  150\n",
      "100 th epoch over  150\n",
      "110 th epoch over  150\n",
      "120 th epoch over  150\n",
      "130 th epoch over  150\n",
      "140 th epoch over  150\n",
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    if epoch%10 == 0:\n",
    "        print(epoch, 'th epoch over ', num_epochs)\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        if reverse_mode:\n",
    "            target_2=torch.randn(int(target.shape[0]/2),1)\n",
    "            for i in range(target_2.shape[0]):\n",
    "                target_2[i]=target[2*i]\n",
    "            target=target_2.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output1, output2 = model.forward(data)\n",
    "        \n",
    "        if hidden_layer == True:\n",
    "            loss = F.binary_cross_entropy(torch.sigmoid(output1),target)+model.net1.beta1*model.net1.wConv.norm()+model.net1.beta2*model.net1.wHidden.norm()+model.net1.beta3*model.net1.wNeu.norm()\n",
    "            loss += F.binary_cross_entropy(torch.sigmoid(output2),target)+model.net2.beta1*model.net2.wConv.norm()+model.net2.beta2*model.net2.wHidden.norm()+model.net2.beta3*model.net2.wNeu.norm()\n",
    "        else:\n",
    "            print('not possible')\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # for train set\n",
    "        model.mode='test'\n",
    "        auc1 = []\n",
    "        auc2 = []\n",
    "        for idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i]=target[2*i]\n",
    "                target=target_2.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model.forward(data)\n",
    "\n",
    "            pred1_sig = torch.sigmoid(output1)\n",
    "            pred2_sig = torch.sigmoid(output2)\n",
    "\n",
    "            pred1=pred1_sig.cpu().detach().numpy().reshape(output1.shape[0])\n",
    "            pred2=pred2_sig.cpu().detach().numpy().reshape(output2.shape[0])\n",
    "\n",
    "            labels=target.cpu().numpy().reshape(output1.shape[0])\n",
    "\n",
    "            try:\n",
    "                auc1.append(metrics.roc_auc_score(labels, pred1))\n",
    "                auc2.append(metrics.roc_auc_score(labels, pred2))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        AUC_training_1 = np.mean(auc1)\n",
    "        AUC_training_2 = np.mean(auc2)\n",
    "\n",
    "        # for valid set\n",
    "        model.mode='test'\n",
    "        auc1 = []\n",
    "        auc2 = []\n",
    "        for idx, (data, target) in enumerate(valid_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            if reverse_mode:\n",
    "                target_2=torch.randn(int(target.shape[0]/2), 1)\n",
    "                for i in range(target_2.shape[0]):\n",
    "                    target_2[i]=target[2*i]\n",
    "                target=target_2.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output1, output2 = model.forward(data)\n",
    "\n",
    "            pred1_sig=torch.sigmoid(output1)\n",
    "            pred2_sig=torch.sigmoid(output2)\n",
    "\n",
    "            pred1 = pred1_sig.cpu().detach().numpy().reshape(output1.shape[0])\n",
    "            pred2 = pred2_sig.cpu().detach().numpy().reshape(output2.shape[0])\n",
    "\n",
    "            labels=target.cpu().numpy().reshape(output1.shape[0])\n",
    "\n",
    "            try:\n",
    "                auc1.append(metrics.roc_auc_score(labels, pred1))\n",
    "                auc2.append(metrics.roc_auc_score(labels, pred2))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        AUC_valid_1 = np.mean(auc1)\n",
    "        AUC_valid_2 = np.mean(auc2)\n",
    "\n",
    "        with open(\"./test/\"+'2020_4_7'+'.txt', \"a\") as file:\n",
    "            file.write(str(AUC_training_1))\n",
    "            file.write('-')\n",
    "            file.write(str(AUC_valid_1))\n",
    "            file.write(':')\n",
    "            file.write(str(AUC_training_2))\n",
    "            file.write('-')\n",
    "            file.write(str(AUC_valid_2))\n",
    "            file.write(', ')\n",
    "        file.close()\n",
    "\n",
    "        if AUC_valid_1 > best_AUC_1:\n",
    "            best_AUC_1 = AUC_valid_1\n",
    "            best_model = model\n",
    "            state = {'conv': model.net1.wConv,\n",
    "                    'rect':model.net1.wRect,\n",
    "                    'wHidden':model.net1.wHidden,\n",
    "                    'wHiddenBias':model.net1.wHiddenBias,\n",
    "                    'wNeu':model.net1.wNeu,\n",
    "                    'wNeuBias':model.net1.wNeuBias}\n",
    "\n",
    "            isExist = os.path.exists('./Models/' + '2020_4_7')\n",
    "            if not isExist:\n",
    "                os.makedirs('./Models/' + '2020_4_7')\n",
    "\n",
    "            torch.save(state, './Models/' + '2020_4_7'+ '/' + str(1) + '.pth')\n",
    "\n",
    "        if AUC_valid_2 > best_AUC_2:\n",
    "            best_AUC_2 = AUC_valid_2\n",
    "            best_model = model\n",
    "            state = {'conv': model.net2.wConv,\n",
    "                    'rect':model.net2.wRect,\n",
    "                    'wHidden':model.net2.wHidden,\n",
    "                    'wHiddenBias':model.net2.wHiddenBias,\n",
    "                    'wNeu':model.net2.wNeu,\n",
    "                    'wNeuBias':model.net2.wNeuBias}\n",
    "\n",
    "            isExist = os.path.exists('./Models/' + '2020_4_7')\n",
    "            if not isExist:\n",
    "                os.makedirs('./Models/' + '2020_4_7')\n",
    "\n",
    "            torch.save(state, './Models/' + '2020_4_7'+ '/' + str(2) + '.pth')\n",
    "\n",
    "with open(\"./test/\"+'2020_4_7'+'.txt', \"a\") as file:\n",
    "    file.write('\\n')\n",
    "    file.write('Best Trainig(validation) AUC : ')\n",
    "    file.write(str(best_AUC_1))\n",
    "    file.write(' and ')\n",
    "    file.write(str(best_AUC_2))\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "\n",
    "print('Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "print('Model Testing')\n",
    "\n",
    "test_loader1 = test_dataset_loader(tf1_test_dataset_path, motif_len)\n",
    "test_loader2 = test_dataset_loader(tf2_test_dataset_path, motif_len)\n",
    "\n",
    "# using the model with best validation AUC\n",
    "checkpoint1 = torch.load('./Models/' + '2020_4_7'+ '/' + str(1) + '.pth')\n",
    "model1 = ConvNet(num_motif_detector,motif_len,pool,hidden_layer,'testing',lr,opt,dropout_rate,beta1,beta2,beta3, device, reverse_complemet_mode=False).to(device)\n",
    "model1.wConv=checkpoint1['conv']\n",
    "model1.wRect=checkpoint1['rect']\n",
    "model1.wHidden=checkpoint1['wHidden']\n",
    "model1.wHiddenBias=checkpoint1['wHiddenBias']\n",
    "model1.wNeu=checkpoint1['wNeu']\n",
    "model1.wNeuBias=checkpoint1['wNeuBias']\n",
    "\n",
    "checkpoint2 = torch.load('./Models/' + '2020_4_7'+ '/' + str(2) + '.pth')\n",
    "model2 = ConvNet(num_motif_detector,motif_len,pool,hidden_layer,'testing',lr,opt,dropout_rate,beta1,beta2,beta3, device, reverse_complemet_mode=False).to(device)\n",
    "model2.wConv=checkpoint2['conv']\n",
    "model2.wRect=checkpoint2['rect']\n",
    "model2.wHidden=checkpoint2['wHidden']\n",
    "model2.wHiddenBias=checkpoint2['wHiddenBias']\n",
    "model2.wNeu=checkpoint2['wNeu']\n",
    "model2.wNeuBias=checkpoint2['wNeuBias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Completed\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model1.mode='test'\n",
    "    auc=[]\n",
    "    \n",
    "    for idx, (data, target) in enumerate(test_loader1):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        if model1.reverse_complemet_mode:\n",
    "            target_2=torch.randn(int(target.shape[0]/2),1)\n",
    "            for i in range(target_2.shape[0]):\n",
    "                target_2[i]=target[2*i]\n",
    "            target=target_2.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model1(data)\n",
    "        pred_sig=torch.sigmoid(output)\n",
    "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "        try:\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    AUC1_test=np.mean(auc)\n",
    "    # print('AUC on test data = ', AUC_test)\n",
    "    with open(\"./test/\"+'2020_4_7'+'.txt', \"a\") as file:\n",
    "        file.write('AUC 1 Test : ')\n",
    "        file.write(str(round(AUC1_test, 5)))\n",
    "        file.write('\\n')\n",
    "    file.close()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model2.mode='test'\n",
    "    auc=[]\n",
    "    \n",
    "    for idx, (data, target) in enumerate(test_loader2):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        if model2.reverse_complemet_mode:\n",
    "            target_2=torch.randn(int(target.shape[0]/2),1)\n",
    "            for i in range(target_2.shape[0]):\n",
    "                target_2[i]=target[2*i]\n",
    "            target=target_2.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model2(data)\n",
    "        pred_sig=torch.sigmoid(output)\n",
    "        pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
    "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
    "        try:\n",
    "            auc.append(metrics.roc_auc_score(labels, pred))\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    AUC2_test=np.mean(auc)\n",
    "    # print('AUC on test data = ', AUC_test)\n",
    "    with open(\"./test/\"+'2020_4_7'+'.txt', \"a\") as file:\n",
    "        file.write('AUC 2 Test : ')\n",
    "        file.write(str(round(AUC2_test, 5)))\n",
    "        file.write('\\n')\n",
    "    file.close()\n",
    "\n",
    "print('Testing Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84c63b404c7ee130c9845246a39403d500621500816a8f9744527cdc65d245ba"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DeepBind')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
